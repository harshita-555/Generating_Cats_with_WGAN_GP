{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gan_cats.ipynb","provenance":[],"collapsed_sections":["B6r_D2VGtPkY","dMYPywH_tZ1q","Fe_5mgy-dPi7"],"toc_visible":true,"mount_file_id":"1phW-nfXoYUxA0O_n8u7Vyu2y-UhdQPJa","authorship_tag":"ABX9TyMNPhDLlOe9XDxxSBvVBhHD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Fe_5mgy-dPi7","colab_type":"text"},"source":["# Downloading cat dataset"]},{"cell_type":"code","metadata":{"id":"w8eJZfSWZCsX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1593252401963,"user_tz":-330,"elapsed":5379,"user":{"displayName":"harshita boonlia","photoUrl":"","userId":"00843089972526149238"}},"outputId":"c80c3d88-6e6a-432d-f792-f215d1154957"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yvLSLFoRfDI8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1593252401964,"user_tz":-330,"elapsed":5370,"user":{"displayName":"harshita boonlia","photoUrl":"","userId":"00843089972526149238"}},"outputId":"07059f2c-c5b5-4e20-f93c-a32a04da91f6"},"source":["cd drive/My\\ Drive/gan_cats"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/gan_cats\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jS9dYVYUldcz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592404624739,"user_tz":-330,"elapsed":1288,"user":{"displayName":"harshita boonlia","photoUrl":"","userId":"00843089972526149238"}},"outputId":"b9bae7e3-83cc-4b93-b06a-725c4a9a7bc7"},"source":["cd Setting up the data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/gan_cats/Deep-learning-with-cats/Setting up the data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"amm7wGTJdgYb","colab_type":"code","colab":{}},"source":["!sh setting_up_script.sh\n","mv cats_bigger_than_64x64 \"../Dataset/cats_64x64\"\n","mv cats_bigger_than_128x128 \"../Dataset/cats_128x128\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmmJcbsKMdLJ","colab_type":"text"},"source":["# WGAN_GP"]},{"cell_type":"markdown","metadata":{"id":"vvAc_JlPvI1G","colab_type":"text"},"source":["## Installing and importing libraries"]},{"cell_type":"code","metadata":{"id":"EqGfrVyqvTuv","colab_type":"code","colab":{}},"source":["!pip install tensorboardX"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bLnUsVGGvU7V","colab_type":"code","colab":{}},"source":["from PIL import Image\n","from torch.utils import data\n","\n","from IPython import display\n","import torch\n","from torch.autograd import Variable\n","from torch import autograd\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import pandas as pd\n","import torchvision\n","from torchvision import datasets, models, transforms \n","from utils import Logger\n","from torchvision import utils\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3pC8tBixHLx","colab_type":"code","colab":{}},"source":["base_dir = \"output_folder\"\n","if (not os.path.exists(base_dir)):\n","   os.mkdir(base_dir)\n","   logs_dir = f\"{base_dir}/logs\"\n","   os.mkdir(logs_dir)\n","   os.mkdir(f\"{base_dir}/images\")\n","   os.mkdir(f\"{base_dir}/models\")\n","logs_dir = f\"{base_dir}/logs\"\n","log_output = open(f\"{logs_dir}/log.txt\", 'w')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCLx8hETVOG4","colab_type":"code","colab":{}},"source":["logger = Logger(logs_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtGr5ctwvfjg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593252413122,"user_tz":-330,"elapsed":12240,"user":{"displayName":"harshita boonlia","photoUrl":"","userId":"00843089972526149238"}},"outputId":"cc0fc99e-e385-49b0-fd50-b14259222e92"},"source":["use_gpu = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n","\n","print(\"Torch version: \", torch.__version__)\n","print(\"GPU Available: {}\".format(use_gpu))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Torch version:  1.5.1+cu101\n","GPU Available: True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XgKGpGIwu9kl","colab_type":"code","colab":{}},"source":["transform = transforms.Compose([\n","\ttransforms.Resize((64,64)),\n","\ttransforms.ToTensor(),\n","\ttransforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJ0VLh7Kvpgp","colab_type":"code","colab":{}},"source":["input_folder = \"Dataset\"\n","data1 = datasets.ImageFolder(root=input_folder, transform=transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"weczCou23676","colab_type":"code","colab":{}},"source":["batch_size=64\n","def generate_random_sample():\n","\twhile True:\n","\t\trandom_indexes = np.random.choice(data1.__len__(), size=batch_size, replace=False)\n","\t\tbatch = [data1[i][0] for i in random_indexes]\n","\t\tyield torch.stack(batch, 0)\n","random_sample = generate_random_sample()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eVe1mVtnZHhq","colab_type":"text"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"0GhRAMQUZGNl","colab_type":"code","colab":{}},"source":["class Generator(torch.nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        # Filters [1024, 512, 256]\n","        # Input_dim = 100\n","        # Output_dim = C (number of channels)\n","        self.main_module = nn.Sequential(\n","            # Z latent vector 100\n","            nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=4, stride=1, padding=0),\n","            nn.BatchNorm2d(num_features=1024),\n","            nn.ReLU(True),\n","\n","            # State (1024x4x4)\n","            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(num_features=512),\n","            nn.ReLU(True),\n","\n","            # State (512x8x8)\n","            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(num_features=256),\n","            nn.ReLU(True),\n","\n","            # State (256x16x16)\n","            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(num_features=128),\n","            nn.ReLU(True),\n","\n","            # State (128x32x32)\n","            nn.ConvTranspose2d(in_channels=128, out_channels=channels, kernel_size=4, stride=2, padding=1))\n","            # output of main module --> Image (Cx64x64)\n","\n","        self.output = nn.Tanh()\n","\n","    def forward(self, x):\n","        x = self.main_module(x)\n","        return self.output(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xKu1deFPoAG","colab_type":"code","colab":{}},"source":["class Generator(torch.nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        # Filters [1024, 512, 256]\n","        # Input_dim = 100\n","        # Output_dim = C (number of channels)\n","        self.main_module = nn.Sequential(\n","            # Z latent vector 100\n","            nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=4, stride=1, padding=0),\n","            nn.SELU(inplace=True),\n","\n","            # State (1024x4x4)\n","            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n","            nn.SELU(inplace=True),\n","\n","            # State (512x8x8)\n","            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n","            nn.SELU(inplace=True),\n","\n","            # State (256x16x16)\n","            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n","            nn.SELU(inplace=True),\n","\n","            # State (128x32x32)\n","            nn.ConvTranspose2d(in_channels=128, out_channels=channels, kernel_size=4, stride=2, padding=1))\n","            # output of main module --> Image (Cx64x64)\n","\n","        self.output = nn.Tanh()\n","\n","    def forward(self, x):\n","        x = self.main_module(x)\n","        return self.output(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJ5RIuo80zAt","colab_type":"code","colab":{}},"source":["class Discriminator(torch.nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        # Filters [256, 512, 1024]\n","        # Input_dim = channels (Cx64x64)\n","        # Output_dim = 1\n","        self.main_module = nn.Sequential(\n","            # Omitting batch normalization in critic because our new penalized training objective (WGAN with gradient penalty) is no longer valid\n","            # in this setting, since we penalize the norm of the critic's gradient with respect to each input independently and not the enitre batch.\n","            # There is not good & fast implementation of layer normalization --> using per instance normalization nn.InstanceNorm2d()\n","            # Image (Cx64x64)\n","            nn.Conv2d(in_channels=channels, out_channels=128, kernel_size=4, stride=2, padding=1),\n","            nn.InstanceNorm2d(128, affine=True),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # State (128x32x32)\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n","            nn.InstanceNorm2d(256, affine=True),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            \n","            # State (256x16x16)\n","            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n","            nn.InstanceNorm2d(512, affine=True),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # State (512x8x8)\n","            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1),\n","            nn.InstanceNorm2d(1024, affine=True),\n","            nn.LeakyReLU(0.2, inplace=True))\n","            # output of main module --> State (1024x4x4)\n","\n","        self.output = nn.Sequential(\n","            # The output of D is no longer a probability, we do not apply sigmoid at the output of D.\n","            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0))\n","\n","\n","    def forward(self, x):\n","        x = self.main_module(x)\n","        return self.output(x)\n","\n","    def feature_extraction(self, x):\n","        # Use discriminator for feature extraction then flatten to vector of 16384\n","        x = self.main_module(x)\n","        return x.view(-1, 1024*4*4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hNqtCyAQd4Q","colab_type":"code","colab":{}},"source":["class Discriminator(torch.nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        # Filters [256, 512, 1024]\n","        # Input_dim = channels (Cx64x64)\n","        # Output_dim = 1\n","        self.main_module = nn.Sequential(\n","            # Omitting batch normalization in critic because our new penalized training objective (WGAN with gradient penalty) is no longer valid\n","            # in this setting, since we penalize the norm of the critic's gradient with respect to each input independently and not the enitre batch.\n","            # There is not good & fast implementation of layer normalization --> using per instance normalization nn.InstanceNorm2d()\n","            # Image (Cx64x64)\n","            nn.Conv2d(in_channels=channels, out_channels=128, kernel_size=4, stride=2, padding=1),\n","            nn.SELU(inplace=True),\n","\n","            # State (128x32x32)\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n","            nn.SELU(inplace=True),\n","            \n","            # State (256x16x16)\n","            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n","            nn.SELU(inplace=True),\n","\n","            # State (512x8x8)\n","            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1),\n","            nn.SELU(inplace=True))\n","            # output of main module --> State (1024x4x4)\n","\n","        self.output = nn.Sequential(\n","            # The output of D is no longer a probability, we do not apply sigmoid at the output of D.\n","            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0))\n","\n","\n","    def forward(self, x):\n","        x = self.main_module(x)\n","        return self.output(x)\n","\n","    def feature_extraction(self, x):\n","        # Use discriminator for feature extraction then flatten to vector of 16384\n","        x = self.main_module(x)\n","        return x.view(-1, 1024*4*4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iINyrZV8VUfH","colab_type":"code","colab":{}},"source":["def calculate_gradient_penalty( real_images, fake_images):\n","        eta = torch.FloatTensor(batch_size,1,1,1).uniform_(0,1)\n","        eta = eta.expand(batch_size, real_images.size(1), real_images.size(2), real_images.size(3))\n","        eta = eta.to(device)\n","        \n","        interpolated = eta * real_images + ((1 - eta) * fake_images)\n","        interpolated = interpolated.to(device)\n","\n","        interpolated = Variable(interpolated, requires_grad=True)\n","\n","        # calculate probability of interpolated examples\n","        out_interpolated = discriminator(interpolated)\n","\n","        # calculate gradients of probabilities with respect to examples\n","        gradients = autograd.grad(outputs=out_interpolated, inputs=interpolated,\n","                                             grad_outputs=torch.ones(out_interpolated.size()).to(device),\n","                                            create_graph=True, retain_graph=True)[0]\n","\n","        grad_penalty = ((gradients.norm(2, dim=1).norm(2, dim=1).norm(2, dim=1) - 1) ** 2).mean() * lambda_gp\n","        return grad_penalty"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rY03ygjC548S","colab_type":"code","colab":{}},"source":["generator = Generator(3)\n","discriminator = Discriminator(3)\n","\n","G_load = 'output_folder/models/G_18001.pth'\n","D_load = 'output_folder/models/D_18001.pth'\n","\n","if G_load != '':\n","  \tgenerator.load_state_dict(torch.load(G_load))\n","if D_load != '':\n","\tdiscriminator.load_state_dict(torch.load(D_load))\n","\n","generator.to(device)\n","discriminator.to(device)\n","\n","n_iters = 15000\n","critic_iter = 5\n","lambda_gp = 10\n","b1 = 0.5\n","b2 = 0.999\n","lr = 1e-4\n","batch_size = 64\n","\n","optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEChCVDfPAf2","colab_type":"code","colab":{}},"source":["import time\n","start = time.time()\n","\n","one = torch.tensor(1, dtype=torch.float)\n","one_neg = one * -1\n","\n","one = one.to(device)\n","one_neg = one_neg.to(device)\n","\n","for g_iter in range(12851,n_iters):\n","    for p in discriminator.parameters():\n","                p.requires_grad = True\n","   \n","    for d_iter in range(critic_iter):\n","                discriminator.zero_grad()\n","\n","                images = random_sample.__next__()\n","                images = Variable(images).to(device)          \n","\n","                d_loss_real = discriminator(images)\n","                d_loss_real = d_loss_real.mean()\n","                d_loss_real.backward(one_neg)\n","\n","                # Train with fake images\n","                z = torch.rand((batch_size, 100, 1, 1))\n","                z = Variable(z).to(device)\n","\n","                fake_images = generator(z)\n","                d_loss_fake = discriminator(fake_images)\n","                d_loss_fake = d_loss_fake.mean()\n","                d_loss_fake.backward(one)\n","\n","                # Train with gradient penalty\n","                gradient_penalty = calculate_gradient_penalty(images.data, fake_images.data)\n","                gradient_penalty.backward()\n","\n","\n","                d_loss = d_loss_fake - d_loss_real + gradient_penalty\n","                Wasserstein_D = d_loss_real - d_loss_fake\n","                optimizer_D.step()\n","                print(f'  Discriminator iteration: {d_iter + 1}/{critic_iter}, loss_fake: {d_loss_fake}, loss_real: {d_loss_real}')\n","\n","    # Generator update\n","    for p in discriminator.parameters():\n","                p.requires_grad = False  # to avoid computation\n","\n","    generator.zero_grad()\n","    z = Variable(torch.randn(batch_size, 100, 1, 1)).to(device)\n","    fake_images = generator(z)\n","    g_loss = discriminator(fake_images)\n","    g_loss = g_loss.mean()\n","    g_loss.backward(one_neg)\n","    g_cost = -g_loss\n","    optimizer_G.step()\n","\n","    display.clear_output(True)\n","    logger.log(Wasserstein_D.item(), d_loss.item(), g_loss.item(), g_iter + 1)\n","\n","    #log_value('errD', Wasserstein_D.item(), g_iter)\n","    #log_value('errD_penalty', d_loss.item(), g_iter)\n","    #log_value('errG', g_loss.item(), g_iter)\n","    print(f' iteration: {g_iter + 1}/{n_iters}')\n","    print(f' Discriminator :loss_fake: {d_loss_fake}, loss_real: {d_loss_real}    Generator :  g_loss: {g_loss}')\n","    \n","    z = Variable(torch.randn(batch_size, 100, 1, 1)).to(device)\n","    samples = generator(z)\n","    samples = samples.mul(0.5).add(0.5)\n","    samples = samples.data.cpu()[:16]\n","    grid = utils.make_grid(samples)\n","    logger.log_images(samples, 16, g_iter + 1)\n","                \n","    if (g_iter) % 50 == 0:\n","          torch.save(generator.state_dict(), '%s/models/G_%d.pth' % (\"output_folder\",g_iter+1))\n","          torch.save(discriminator.state_dict(), '%s/models/D_%d.pth' % (\"output_folder\", g_iter+1))\n","\n","\n","end = time.time()\n","print('Time of training-{}'.format((end - start)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x2BPEhc2_3fB","colab_type":"code","colab":{}},"source":["torch.save(generator.state_dict(), '%s/models/G_%d.pth' % (\"output_folder\",g_iter+1))\n","torch.save(discriminator.state_dict(), '%s/models/D_%d.pth' % (\"output_folder\", g_iter+1))"],"execution_count":null,"outputs":[]}]}